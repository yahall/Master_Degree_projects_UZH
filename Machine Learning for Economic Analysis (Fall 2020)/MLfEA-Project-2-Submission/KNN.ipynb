{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this file, we are using the pre-processed accidents data to analyse the relationship between the underlying variables. Especially, it is our aim to assess the behaviour of the features in their co-existence with other features, portray the predictive power of multiple classification models as well assign importance to selected feature variables with respect to their effect on the variable of interest. Doing so, we will perform a short data analysis to visually inspect patterns, obtain relation strengths through application of numerous classification algorithms and perform a type of feature selection in which we assign feature importance through a range of selection techniques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import matplotlib.lines as mlines\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, PolynomialFeatures \n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, bernoulli\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Analysis\n",
    "In this part, we will quickly analyse the underlying behaviour of our feature variables to assess their distributional forms, observe their co-existance with other variables and define, through visual inspection, to what decree individual features might have an impact on the classification framework. As such, we will perform a first analysis that is likely to give preliminary results expected to be captured by the subsequent models for prediciton and selection.\n",
    "\n",
    "Model Parameters\n",
    "As was shortly introduced in the data preparation notebook, we obtain a dataset consisting of 16 feature variables. These are:\n",
    "\n",
    "Accident Severity: A 3-level categorical character string indicating the severity of an accident. Ranging from Slight over Severe to Lethal.\n",
    "\n",
    "Light Conditions: A categorical variable covering 7 specific light conditions.\n",
    "\n",
    "Weather Conditions: A categorical variable covering 7 specific weather conditions.\n",
    "\n",
    "Road Surface Conditions: A categorical variable covering 5 specific surface conditions.\n",
    "\n",
    "Hour of day: A continuous variable previously defined as \"time of accident\". This variable was transformed into hourly intervals to obtain a better interpretability and improve policy predictions. As such, we defined 23 intervals covering each hour of the day.\n",
    "\n",
    "Day of Week: A categorical variable covering the 7 specific days of the week which are indicated as Monday to Sunday.\n",
    "\n",
    "Sex of Driver: The gender of the driver causing the accident, given as male or female.\n",
    "\n",
    "Age of Driver: A categoorical variable covering the age of the driver in bins of 5-10 years, respectively. Starting at 18-20, then in 5-10 year intervals approaching 75 and ending on 75+.\n",
    "\n",
    "Speed Limit: The respective speed limit where the accident occured.\n",
    "\n",
    "Vehicle Type: A categorical variable previously given by multiple sub-categories for cars and motorcycles. These sub-categories were merged into either the major category cars or motorcycles.\n",
    "\n",
    "Engine Capacity: The engine capacity of the vehicle causing the accident. Defined individually for cars and motorcycles. Both categories are assigned into a 4-level cluster.\n",
    "\n",
    "Junction Detail: Covers details on environment surrounding the accident. Summarised into a 3-level categorical feature with levels junction, open street and roundabout. This is to indicate in which street setting the accident took place.\n",
    "\n",
    "Multiple Vehicles involved: A binary feature indicating 1 if more than one car was involved in the accident.\n",
    "\n",
    "Month + Year: Features indicating in which month and which year the accident occured.\n",
    "\n",
    "Age of vehicle: A categorical feature indicating the age of the vehicle at accident date. Binned into 4 levels, ranging from 0-1 to +10 years.\n",
    "\n",
    "We will now perform a short data analysis with these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Accident_Index                1482372\n",
       "Accident_Severity             1482372\n",
       "Road_Class                    1482372\n",
       "Speed_limit                   1482372\n",
       "Junction_Detail               1482372\n",
       "Light_Conditions              1482372\n",
       "Weather_Conditions            1482372\n",
       "Road_Surface_Conditions       1482372\n",
       "Hour_of_Day                   1482372\n",
       "Year                          1482372\n",
       "Month                         1482372\n",
       "Day_of_Week                   1482372\n",
       "Multiple_Vehicles_involved    1482372\n",
       "Urban_Area                    1482372\n",
       "Vehicle_Type                  1482372\n",
       "Sex_of_Driver                 1482372\n",
       "Age_of_Driver                 1482372\n",
       "Engine_Capacity_(CC)          1482372\n",
       "Age_of_Vehicle                1482372\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "acc = pd.read_csv('UK_accidents_preprocessed.csv')\n",
    "acc.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Accident_Index                0\n",
       "Accident_Severity             0\n",
       "Road_Class                    0\n",
       "Speed_limit                   0\n",
       "Junction_Detail               0\n",
       "Light_Conditions              0\n",
       "Weather_Conditions            0\n",
       "Road_Surface_Conditions       0\n",
       "Hour_of_Day                   0\n",
       "Year                          0\n",
       "Month                         0\n",
       "Day_of_Week                   0\n",
       "Multiple_Vehicles_involved    0\n",
       "Urban_Area                    0\n",
       "Vehicle_Type                  0\n",
       "Sex_of_Driver                 0\n",
       "Age_of_Driver                 0\n",
       "Engine_Capacity_(CC)          0\n",
       "Age_of_Vehicle                0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "acc.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, the variables which were already in the correct order as characters are transformed  is transformed into characters of 1 to 3. Here, 1 stands for slight and 3 for lethal accident\n",
    "\n",
    "# re-assign the only nan value\n",
    "\n",
    "acc['Age_of_Vehicle'] = np.where(acc['Age_of_Vehicle'].isna() == True, 'New (0-1)', acc['Age_of_Vehicle'])\n",
    "acc['Day_of_Week'] = np.where(acc['Day_of_Week'] == 'We', 'Wednesday', acc['Day_of_Week'])\n",
    "acc['Age_of_Driver'] = np.where(acc['Age_of_Driver'].isna() == True, '21-25', acc['Age_of_Driver'])\n",
    "acc['Engine_Capacity_(CC)'] = np.where(acc['Engine_Capacity_(CC)'].isna() == True, '0-125cc', acc['Engine_Capacity_(CC)'])\n",
    "\n",
    "var = ['Accident_Severity', 'Road_Class', 'Junction_Detail', 'Light_Conditions', 'Weather_Conditions', 'Road_Surface_Conditions', 'Vehicle_Type', 'Sex_of_Driver'] \n",
    "\n",
    "for i in acc[var]: \n",
    "  acc[i + '_Code'] = pd.factorize(acc[i])[0] + 1\n",
    "\n",
    "# Then, we assign the day of the week codes back: \n",
    "\n",
    "acc['Day_of_Week_Code'] = np.zeros\n",
    "acc['Day_of_Week_Code'].loc[acc['Day_of_Week'] == 'Monday'] = 1\n",
    "acc['Day_of_Week_Code'].loc[acc['Day_of_Week'] == 'Tuesday'] = 2\n",
    "acc['Day_of_Week_Code'].loc[acc['Day_of_Week'] == 'Wednesday'] = 3\n",
    "acc['Day_of_Week_Code'].loc[acc['Day_of_Week'] == 'Thursday'] = 4\n",
    "acc['Day_of_Week_Code'].loc[acc['Day_of_Week'] == 'Friday'] = 5\n",
    "acc['Day_of_Week_Code'].loc[acc['Day_of_Week'] == 'Saturday'] = 6\n",
    "acc['Day_of_Week_Code'].loc[acc['Day_of_Week'] == 'Sunday'] = 7\n",
    "\n",
    "acc['Day_of_Week_Code'] = acc['Day_of_Week_Code'].astype(int)\n",
    "\n",
    "# Next, we do the same for Age of Vehicle\n",
    "\n",
    "acc['Age_of_Vehicle_Code'] = np.zeros\n",
    "acc['Age_of_Vehicle_Code'].loc[acc['Age_of_Vehicle'] == 'New (0-1)'] = 1\n",
    "acc['Age_of_Vehicle_Code'].loc[acc['Age_of_Vehicle'] == '2-5'] = 2\n",
    "acc['Age_of_Vehicle_Code'].loc[acc['Age_of_Vehicle'] == '6-10'] = 3\n",
    "acc['Age_of_Vehicle_Code'].loc[acc['Age_of_Vehicle'] == '>10'] = 4\n",
    "\n",
    "acc['Age_of_Vehicle_Code'] = acc['Age_of_Vehicle_Code'].astype(int)\n",
    "\n",
    "# And for Age of Driver bins\n",
    "\n",
    "acc['Age_of_Driver_Code'] = np.zeros\n",
    "acc['Age_of_Driver_Code'].loc[acc['Age_of_Driver'] == '<18'] = 1\n",
    "acc['Age_of_Driver_Code'].loc[acc['Age_of_Driver'] == '18-20'] = 2\n",
    "acc['Age_of_Driver_Code'].loc[acc['Age_of_Driver'] == '21-25'] = 3\n",
    "acc['Age_of_Driver_Code'].loc[acc['Age_of_Driver'] == '26-35'] = 4\n",
    "acc['Age_of_Driver_Code'].loc[acc['Age_of_Driver'] == '36-45'] = 5\n",
    "acc['Age_of_Driver_Code'].loc[acc['Age_of_Driver'] == '46-55'] = 6\n",
    "acc['Age_of_Driver_Code'].loc[acc['Age_of_Driver'] == '56-65'] = 7\n",
    "acc['Age_of_Driver_Code'].loc[acc['Age_of_Driver'] == '66-75'] = 8\n",
    "acc['Age_of_Driver_Code'].loc[acc['Age_of_Driver'] == '>75'] = 9\n",
    "\n",
    "acc['Age_of_Driver_Code'] = acc['Age_of_Driver_Code'].astype(int)\n",
    "\n",
    "\n",
    "# As well as for Engine Capacity \n",
    "\n",
    "acc['Engine_Capacity_(CC)_Code'] = np.zeros\n",
    "acc['Engine_Capacity_(CC)_Code'].loc[acc['Engine_Capacity_(CC)'] == '0-125cc'] = 1\n",
    "acc['Engine_Capacity_(CC)_Code'].loc[acc['Engine_Capacity_(CC)'] == '126-350cc'] = 2\n",
    "acc['Engine_Capacity_(CC)_Code'].loc[acc['Engine_Capacity_(CC)'] == '351-600cc'] = 3\n",
    "acc['Engine_Capacity_(CC)_Code'].loc[acc['Engine_Capacity_(CC)'] == '601-1150cc'] = 4\n",
    "acc['Engine_Capacity_(CC)_Code'].loc[acc['Engine_Capacity_(CC)'] == '1151-1999cc'] = 5\n",
    "acc['Engine_Capacity_(CC)_Code'].loc[acc['Engine_Capacity_(CC)'] == '2000-2999cc'] = 6\n",
    "acc['Engine_Capacity_(CC)_Code'].loc[acc['Engine_Capacity_(CC)'] == '3000-3999cc'] = 7\n",
    "acc['Engine_Capacity_(CC)_Code'].loc[acc['Engine_Capacity_(CC)'] == '>4000cc'] = 8\n",
    "\n",
    "acc['Engine_Capacity_(CC)_Code'] = acc['Engine_Capacity_(CC)_Code'].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with the variables sorted, we are able to have a look at their description. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        Speed_limit   Hour_of_Day          Year         Month  \\\n",
       "count  1.482372e+06  1.482372e+06  1.482372e+06  1.482372e+06   \n",
       "mean   3.922839e+01  1.362957e+01  2.011485e+03  6.617869e+00   \n",
       "std    1.429680e+01  5.193850e+00  4.273592e+00  3.444451e+00   \n",
       "min    1.000000e+01  0.000000e+00  2.005000e+03  1.000000e+00   \n",
       "25%    3.000000e+01  1.000000e+01  2.008000e+03  4.000000e+00   \n",
       "50%    3.000000e+01  1.400000e+01  2.011000e+03  7.000000e+00   \n",
       "75%    5.000000e+01  1.700000e+01  2.015000e+03  1.000000e+01   \n",
       "max    7.000000e+01  2.300000e+01  2.019000e+03  1.200000e+01   \n",
       "\n",
       "       Multiple_Vehicles_involved    Urban_Area  Accident_Severity_Code  \\\n",
       "count                1.482372e+06  1.482372e+06            1.482372e+06   \n",
       "mean                 7.076746e-01  6.281608e-01            1.177874e+00   \n",
       "std                  4.548312e-01  4.832959e-01            4.175724e-01   \n",
       "min                  0.000000e+00  0.000000e+00            1.000000e+00   \n",
       "25%                  0.000000e+00  0.000000e+00            1.000000e+00   \n",
       "50%                  1.000000e+00  1.000000e+00            1.000000e+00   \n",
       "75%                  1.000000e+00  1.000000e+00            1.000000e+00   \n",
       "max                  1.000000e+00  1.000000e+00            3.000000e+00   \n",
       "\n",
       "       Road_Class_Code  Junction_Detail_Code  Light_Conditions_Code  \\\n",
       "count     1.482372e+06          1.482372e+06           1.482372e+06   \n",
       "mean      1.960208e+00          1.655555e+00           1.674603e+00   \n",
       "std       1.125635e+00          6.472355e-01           1.177433e+00   \n",
       "min       1.000000e+00          1.000000e+00           1.000000e+00   \n",
       "25%       1.000000e+00          1.000000e+00           1.000000e+00   \n",
       "50%       2.000000e+00          2.000000e+00           1.000000e+00   \n",
       "75%       3.000000e+00          2.000000e+00           3.000000e+00   \n",
       "max       5.000000e+00          3.000000e+00           5.000000e+00   \n",
       "\n",
       "       Weather_Conditions_Code  Road_Surface_Conditions_Code  \\\n",
       "count             1.482372e+06                  1.482372e+06   \n",
       "mean              1.417309e+00                  1.362196e+00   \n",
       "std               1.071775e+00                  5.769500e-01   \n",
       "min               1.000000e+00                  1.000000e+00   \n",
       "25%               1.000000e+00                  1.000000e+00   \n",
       "50%               1.000000e+00                  1.000000e+00   \n",
       "75%               1.000000e+00                  2.000000e+00   \n",
       "max               8.000000e+00                  5.000000e+00   \n",
       "\n",
       "       Vehicle_Type_Code  Sex_of_Driver_Code  Day_of_Week_Code  \\\n",
       "count       1.482372e+06        1.482372e+06      1.482372e+06   \n",
       "mean        1.085856e+00        1.666635e+00      3.929747e+00   \n",
       "std         2.801509e-01        4.714159e-01      1.937186e+00   \n",
       "min         1.000000e+00        1.000000e+00      1.000000e+00   \n",
       "25%         1.000000e+00        1.000000e+00      2.000000e+00   \n",
       "50%         1.000000e+00        2.000000e+00      4.000000e+00   \n",
       "75%         1.000000e+00        2.000000e+00      6.000000e+00   \n",
       "max         2.000000e+00        2.000000e+00      7.000000e+00   \n",
       "\n",
       "       Age_of_Vehicle_Code  Age_of_Driver_Code  Engine_Capacity_(CC)_Code  \n",
       "count         1.482372e+06        1.482372e+06               1.482372e+06  \n",
       "mean          2.906279e+00        4.698292e+00               4.824370e+00  \n",
       "std           9.644327e-01        1.889562e+00               1.019235e+00  \n",
       "min           1.000000e+00        1.000000e+00               1.000000e+00  \n",
       "25%           2.000000e+00        3.000000e+00               5.000000e+00  \n",
       "50%           3.000000e+00        5.000000e+00               5.000000e+00  \n",
       "75%           4.000000e+00        6.000000e+00               5.000000e+00  \n",
       "max           4.000000e+00        9.000000e+00               8.000000e+00  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Speed_limit</th>\n      <th>Hour_of_Day</th>\n      <th>Year</th>\n      <th>Month</th>\n      <th>Multiple_Vehicles_involved</th>\n      <th>Urban_Area</th>\n      <th>Accident_Severity_Code</th>\n      <th>Road_Class_Code</th>\n      <th>Junction_Detail_Code</th>\n      <th>Light_Conditions_Code</th>\n      <th>Weather_Conditions_Code</th>\n      <th>Road_Surface_Conditions_Code</th>\n      <th>Vehicle_Type_Code</th>\n      <th>Sex_of_Driver_Code</th>\n      <th>Day_of_Week_Code</th>\n      <th>Age_of_Vehicle_Code</th>\n      <th>Age_of_Driver_Code</th>\n      <th>Engine_Capacity_(CC)_Code</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1.482372e+06</td>\n      <td>1.482372e+06</td>\n      <td>1.482372e+06</td>\n      <td>1.482372e+06</td>\n      <td>1.482372e+06</td>\n      <td>1.482372e+06</td>\n      <td>1.482372e+06</td>\n      <td>1.482372e+06</td>\n      <td>1.482372e+06</td>\n      <td>1.482372e+06</td>\n      <td>1.482372e+06</td>\n      <td>1.482372e+06</td>\n      <td>1.482372e+06</td>\n      <td>1.482372e+06</td>\n      <td>1.482372e+06</td>\n      <td>1.482372e+06</td>\n      <td>1.482372e+06</td>\n      <td>1.482372e+06</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.922839e+01</td>\n      <td>1.362957e+01</td>\n      <td>2.011485e+03</td>\n      <td>6.617869e+00</td>\n      <td>7.076746e-01</td>\n      <td>6.281608e-01</td>\n      <td>1.177874e+00</td>\n      <td>1.960208e+00</td>\n      <td>1.655555e+00</td>\n      <td>1.674603e+00</td>\n      <td>1.417309e+00</td>\n      <td>1.362196e+00</td>\n      <td>1.085856e+00</td>\n      <td>1.666635e+00</td>\n      <td>3.929747e+00</td>\n      <td>2.906279e+00</td>\n      <td>4.698292e+00</td>\n      <td>4.824370e+00</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.429680e+01</td>\n      <td>5.193850e+00</td>\n      <td>4.273592e+00</td>\n      <td>3.444451e+00</td>\n      <td>4.548312e-01</td>\n      <td>4.832959e-01</td>\n      <td>4.175724e-01</td>\n      <td>1.125635e+00</td>\n      <td>6.472355e-01</td>\n      <td>1.177433e+00</td>\n      <td>1.071775e+00</td>\n      <td>5.769500e-01</td>\n      <td>2.801509e-01</td>\n      <td>4.714159e-01</td>\n      <td>1.937186e+00</td>\n      <td>9.644327e-01</td>\n      <td>1.889562e+00</td>\n      <td>1.019235e+00</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000e+01</td>\n      <td>0.000000e+00</td>\n      <td>2.005000e+03</td>\n      <td>1.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>3.000000e+01</td>\n      <td>1.000000e+01</td>\n      <td>2.008000e+03</td>\n      <td>4.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>2.000000e+00</td>\n      <td>2.000000e+00</td>\n      <td>3.000000e+00</td>\n      <td>5.000000e+00</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>3.000000e+01</td>\n      <td>1.400000e+01</td>\n      <td>2.011000e+03</td>\n      <td>7.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>2.000000e+00</td>\n      <td>2.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>2.000000e+00</td>\n      <td>4.000000e+00</td>\n      <td>3.000000e+00</td>\n      <td>5.000000e+00</td>\n      <td>5.000000e+00</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>5.000000e+01</td>\n      <td>1.700000e+01</td>\n      <td>2.015000e+03</td>\n      <td>1.000000e+01</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>3.000000e+00</td>\n      <td>2.000000e+00</td>\n      <td>3.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>2.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>2.000000e+00</td>\n      <td>6.000000e+00</td>\n      <td>4.000000e+00</td>\n      <td>6.000000e+00</td>\n      <td>5.000000e+00</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>7.000000e+01</td>\n      <td>2.300000e+01</td>\n      <td>2.019000e+03</td>\n      <td>1.200000e+01</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>3.000000e+00</td>\n      <td>5.000000e+00</td>\n      <td>3.000000e+00</td>\n      <td>5.000000e+00</td>\n      <td>8.000000e+00</td>\n      <td>5.000000e+00</td>\n      <td>2.000000e+00</td>\n      <td>2.000000e+00</td>\n      <td>7.000000e+00</td>\n      <td>4.000000e+00</td>\n      <td>9.000000e+00</td>\n      <td>8.000000e+00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "acc.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN - Classification with subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Accident_Index                  592949\n",
       "Accident_Severity               592949\n",
       "Road_Class                      592949\n",
       "Speed_limit                     592949\n",
       "Junction_Detail                 592949\n",
       "Light_Conditions                592949\n",
       "Weather_Conditions              592949\n",
       "Road_Surface_Conditions         592949\n",
       "Hour_of_Day                     592949\n",
       "Year                            592949\n",
       "Month                           592949\n",
       "Day_of_Week                     592949\n",
       "Multiple_Vehicles_involved      592949\n",
       "Urban_Area                      592949\n",
       "Vehicle_Type                    592949\n",
       "Sex_of_Driver                   592949\n",
       "Age_of_Driver                   592949\n",
       "Engine_Capacity_(CC)            592949\n",
       "Age_of_Vehicle                  592949\n",
       "Accident_Severity_Code          592949\n",
       "Road_Class_Code                 592949\n",
       "Junction_Detail_Code            592949\n",
       "Light_Conditions_Code           592949\n",
       "Weather_Conditions_Code         592949\n",
       "Road_Surface_Conditions_Code    592949\n",
       "Vehicle_Type_Code               592949\n",
       "Sex_of_Driver_Code              592949\n",
       "Day_of_Week_Code                592949\n",
       "Age_of_Vehicle_Code             592949\n",
       "Age_of_Driver_Code              592949\n",
       "Engine_Capacity_(CC)_Code       592949\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Creating a 40% subsample (592'949 datapoints)\n",
    "acc_sub = acc.sample(frac=0.4, random_state=1)\n",
    "acc_sub.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the features\n",
    "features = acc_sub[acc_sub.columns[acc_sub.columns.isin(['Road_Class', 'Junction_Detail', 'Light_Conditions', \n",
    "                                             'Weather_Conditions', 'Road_Surface_Conditions', 'Vehicle_Type', 'Sex_of_Driver', \n",
    "                                             'Day_of_Week', 'Engine_Capacity_(CC)', 'Age_of_Driver', 'Age_of_Vehicle',\n",
    "                                             'Multiple_Vehicles_involved', 'Urban_Area', 'Month', 'Year', 'Hour_of_Day', 'Speed_limit'])]]\n",
    "                                             \n",
    "# Bring them into the desired format\n",
    "features = features.astype(object)\n",
    "features[['Multiple_Vehicles_involved','Urban_Area']] = features[['Multiple_Vehicles_involved','Urban_Area']].astype(int)\n",
    "\n",
    "# Apply one hot encoding to get category-indicating variables for each categorical feature\n",
    "X = pd.get_dummies(features, drop_first=False).to_numpy()\n",
    "\n",
    "# Get the label in the right format\n",
    "y = acc_sub['Accident_Severity'].astype(object).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a train-test split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test accuracy with k=1 neighbors is 0.7382\n",
      "[[   46   375  1199]\n",
      " [  327  3330 14266]\n",
      " [ 1127 13756 84164]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Fatal       0.03      0.03      0.03      1620\n",
      "     Serious       0.19      0.19      0.19     17923\n",
      "      Slight       0.84      0.85      0.85     99047\n",
      "\n",
      "    accuracy                           0.74    118590\n",
      "   macro avg       0.36      0.35      0.35    118590\n",
      "weighted avg       0.73      0.74      0.74    118590\n",
      "\n",
      "Test accuracy with k=2 neighbors is 0.6564\n",
      "[[   88   590   942]\n",
      " [  657  5648 11618]\n",
      " [ 2215 24724 72108]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Fatal       0.03      0.05      0.04      1620\n",
      "     Serious       0.18      0.32      0.23     17923\n",
      "      Slight       0.85      0.73      0.78     99047\n",
      "\n",
      "    accuracy                           0.66    118590\n",
      "   macro avg       0.35      0.37      0.35    118590\n",
      "weighted avg       0.74      0.66      0.69    118590\n",
      "\n",
      "Test accuracy with k=3 neighbors is 0.7935\n",
      "[[   56   221  1343]\n",
      " [  383  1808 15732]\n",
      " [ 1032  5772 92243]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Fatal       0.04      0.03      0.04      1620\n",
      "     Serious       0.23      0.10      0.14     17923\n",
      "      Slight       0.84      0.93      0.89     99047\n",
      "\n",
      "    accuracy                           0.79    118590\n",
      "   macro avg       0.37      0.36      0.35    118590\n",
      "weighted avg       0.74      0.79      0.76    118590\n",
      "\n",
      "Test accuracy with k=4 neighbors is 0.7739\n",
      "[[   11   346  1263]\n",
      " [   81  3000 14842]\n",
      " [  172 10113 88762]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Fatal       0.04      0.01      0.01      1620\n",
      "     Serious       0.22      0.17      0.19     17923\n",
      "      Slight       0.85      0.90      0.87     99047\n",
      "\n",
      "    accuracy                           0.77    118590\n",
      "   macro avg       0.37      0.36      0.36    118590\n",
      "weighted avg       0.74      0.77      0.76    118590\n",
      "\n",
      "Test accuracy with k=5 neighbors is 0.8158\n",
      "[[   15   200  1405]\n",
      " [   85  1468 16370]\n",
      " [  159  3628 95260]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Fatal       0.06      0.01      0.02      1620\n",
      "     Serious       0.28      0.08      0.13     17923\n",
      "      Slight       0.84      0.96      0.90     99047\n",
      "\n",
      "    accuracy                           0.82    118590\n",
      "   macro avg       0.39      0.35      0.35    118590\n",
      "weighted avg       0.75      0.82      0.77    118590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop for different values for k\n",
    "k_range = range(1, 6)\n",
    "\n",
    "for k in k_range:\n",
    "    clf = KNeighborsClassifier(n_neighbors=k, n_jobs=-1) #n_jobs=-1 means that all processes who can be parallelized among cpu cores are performed parallelly\n",
    "    clf.fit(Xtrain, ytrain)\n",
    "    yhat_knn = clf.predict(Xtest)\n",
    "    accuracy = np.mean(yhat_knn == ytest)\n",
    "    print('Test accuracy with k=%.0f neighbors is %.4f' % (k, accuracy))\n",
    "    print(confusion_matrix(ytest, yhat_knn))\n",
    "    print(classification_report(ytest, yhat_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[   15   200  1405]\n",
      " [   85  1468 16370]\n",
      " [  159  3628 95260]]\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Fatal       0.06      0.01      0.02      1620\n",
      "     Serious       0.28      0.08      0.13     17923\n",
      "      Slight       0.84      0.96      0.90     99047\n",
      "\n",
      "    accuracy                           0.82    118590\n",
      "   macro avg       0.39      0.35      0.35    118590\n",
      "weighted avg       0.75      0.82      0.77    118590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n",
    "clf.fit(Xtrain, ytrain)\n",
    "yhat_knn = clf.predict(Xtest)\n",
    "print('Confusion Matrix')\n",
    "print('')\n",
    "print(confusion_matrix(ytest, yhat_knn))\n",
    "print('')\n",
    "print('Classification Report')\n",
    "print('')\n",
    "print(classification_report(ytest, yhat_knn))"
   ]
  },
  {
   "source": [
    "## KNN - Classification with a balanced dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a balanced dataset with 20'000 observations of each severity category\n",
    "acc_balanced = pd.concat([acc[acc['Accident_Severity'] == 'Slight'].sample(n=20000, random_state=1),\n",
    "acc[acc['Accident_Severity'] == 'Serious'].sample(n=20000, random_state=1),\n",
    "acc[acc['Accident_Severity'] == 'Fatal'].sample(n=20000, random_state=1)])\n",
    "\n",
    "# Create a dataset consisting of the remaining datapoints that are not included in the balanced set\n",
    "acc_sub_res = pd.concat([acc_sub, acc_balanced, acc_balanced]).drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the features for the balanced dataset\n",
    "features = acc_balanced[acc_balanced.columns[acc_balanced.columns.isin(['Road_Class', 'Junction_Detail', 'Light_Conditions', \n",
    "                                             'Weather_Conditions', 'Road_Surface_Conditions', 'Vehicle_Type', 'Sex_of_Driver', \n",
    "                                             'Day_of_Week', 'Engine_Capacity_(CC)', 'Age_of_Driver', 'Age_of_Vehicle',\n",
    "                                             'Multiple_Vehicles_involved', 'Urban_Area', 'Month', 'Year', 'Hour_of_Day', 'Speed_limit'])]]\n",
    "                                             \n",
    "# Bring them into the desired format\n",
    "features = features.astype(object)\n",
    "features[['Multiple_Vehicles_involved','Urban_Area']] = features[['Multiple_Vehicles_involved','Urban_Area']].astype(int)\n",
    "\n",
    "# Apply one hot encoding to get category-indicating variables for each categorical feature\n",
    "X = pd.get_dummies(features, drop_first=False).to_numpy()\n",
    "\n",
    "# Get the label in the right format\n",
    "y = acc_balanced['Accident_Severity'].astype(object).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the features for the remaining dataset\n",
    "features_res = acc_sub_res[acc_sub_res.columns[acc_sub_res.columns.isin(['Road_Class', 'Junction_Detail', 'Light_Conditions', \n",
    "                                             'Weather_Conditions', 'Road_Surface_Conditions', 'Vehicle_Type', 'Sex_of_Driver', \n",
    "                                             'Day_of_Week', 'Engine_Capacity_(CC)', 'Age_of_Driver', 'Age_of_Vehicle',\n",
    "                                             'Multiple_Vehicles_involved', 'Urban_Area', 'Month', 'Year', 'Hour_of_Day', 'Speed_limit'])]]\n",
    "                                             \n",
    "# Bring them into the desired format\n",
    "features_res = features_res.astype(object)\n",
    "features_res[['Multiple_Vehicles_involved','Urban_Area']] = features_res[['Multiple_Vehicles_involved','Urban_Area']].astype(int)\n",
    "\n",
    "# Apply one hot encoding to get category-indicating variables for each categorical feature\n",
    "X_res = pd.get_dummies(features_res, drop_first=False).to_numpy()\n",
    "\n",
    "# Get the label in the right format\n",
    "y_res = acc_sub_res['Accident_Severity'].astype(object).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a train-test split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include the residual X values, that are not included in the balanced dataset, to the test dataset.\n",
    "Xtest = np.concatenate([Xtest, X_res])\n",
    "\n",
    "# Include the residual y values, that are not included in the balanced dataset, to the test dataset.\n",
    "ytest = np.concatenate([ytest, y_res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  2684   1062    536]\n",
      " [ 33525  29466  21981]\n",
      " [144593 165855 181417]]\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Fatal       0.01      0.63      0.03      4282\n",
      "     Serious       0.15      0.35      0.21     84972\n",
      "      Slight       0.89      0.37      0.52    491865\n",
      "\n",
      "    accuracy                           0.37    581119\n",
      "   macro avg       0.35      0.45      0.25    581119\n",
      "weighted avg       0.78      0.37      0.47    581119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n",
    "clf.fit(Xtrain, ytrain)\n",
    "yhat_knn = clf.predict(Xtest)\n",
    "print('Confusion Matrix')\n",
    "print('')\n",
    "print(confusion_matrix(ytest, yhat_knn))\n",
    "print('')\n",
    "print('Classification Report')\n",
    "print('')\n",
    "print(classification_report(ytest, yhat_knn))"
   ]
  },
  {
   "source": [
    "## KNN - Classification (binary)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reclassify 'Fatal' and 'Serious' accidents to a new class 'Serious & Fatal' to make it a binary KNN\n",
    "acc_sub.loc[acc['Accident_Severity'] == 'Fatal', ['Accident_Severity']] = 'Serious & Fatal'\n",
    "acc_sub.loc[acc['Accident_Severity'] == 'Serious', ['Accident_Severity']] = 'Serious & Fatal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the features\n",
    "features = acc_sub[acc_sub.columns[acc_sub.columns.isin(['Road_Class', 'Junction_Detail', 'Light_Conditions', \n",
    "                                             'Weather_Conditions', 'Road_Surface_Conditions', 'Vehicle_Type', 'Sex_of_Driver', \n",
    "                                             'Day_of_Week', 'Engine_Capacity_(CC)', 'Age_of_Driver', 'Age_of_Vehicle',\n",
    "                                             'Multiple_Vehicles_involved', 'Urban_Area', 'Month', 'Year', 'Hour_of_Day', 'Speed_limit'])]]\n",
    "                                             \n",
    "# Bring them into the desired format\n",
    "features = features.astype(object)\n",
    "features[['Multiple_Vehicles_involved','Urban_Area']] = features[['Multiple_Vehicles_involved','Urban_Area']].astype(int)\n",
    "\n",
    "# Apply one hot encoding to get category-indicating variables for each categorical feature\n",
    "X = pd.get_dummies(features, drop_first=False).to_numpy()\n",
    "\n",
    "# Get the label in the right format\n",
    "y = acc_sub['Accident_Severity'].astype(object).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a train-test split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[ 1768 17775]\n",
      " [ 3787 95260]]\n",
      "\n",
      "Classification Report\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Serious & Fatal       0.32      0.09      0.14     19543\n",
      "         Slight       0.84      0.96      0.90     99047\n",
      "\n",
      "       accuracy                           0.82    118590\n",
      "      macro avg       0.58      0.53      0.52    118590\n",
      "   weighted avg       0.76      0.82      0.77    118590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n",
    "clf.fit(Xtrain, ytrain)\n",
    "yhat_knn = clf.predict(Xtest)\n",
    "print('Confusion Matrix')\n",
    "print('')\n",
    "print(confusion_matrix(ytest, yhat_knn))\n",
    "print('')\n",
    "print('Classification Report')\n",
    "print('')\n",
    "print(classification_report(ytest, yhat_knn))"
   ]
  },
  {
   "source": [
    "## KNN - Classification (binary) with a balanced dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a balanced dataset with 20'000 observations of each severity category\n",
    "acc_balanced2 = pd.concat([acc_sub[acc_sub['Accident_Severity'] == 'Slight'].sample(n=30000, random_state=1),\n",
    "acc_sub[acc_sub['Accident_Severity'] == 'Serious & Fatal'].sample(n=30000, random_state=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset consisting of the remaining datapoints that are not included in the balanced set\n",
    "acc_sub_res = pd.concat([acc_sub, acc_balanced2, acc_balanced2]).drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the features\n",
    "features = acc_balanced2[acc_balanced2.columns[acc_balanced2.columns.isin(['Road_Class', 'Junction_Detail', 'Light_Conditions', \n",
    "                                             'Weather_Conditions', 'Road_Surface_Conditions', 'Vehicle_Type', 'Sex_of_Driver', \n",
    "                                             'Day_of_Week', 'Engine_Capacity_(CC)', 'Age_of_Driver', 'Age_of_Vehicle',\n",
    "                                             'Multiple_Vehicles_involved', 'Urban_Area', 'Month', 'Year', 'Hour_of_Day', 'Speed_limit'])]]\n",
    "                                             \n",
    "# Bring them into the desired format\n",
    "features = features.astype(object)\n",
    "features[['Multiple_Vehicles_involved','Urban_Area']] = features[['Multiple_Vehicles_involved','Urban_Area']].astype(int)\n",
    "\n",
    "# Apply one hot encoding to get category-indicating variables for each categorical feature\n",
    "X = pd.get_dummies(features, drop_first=False).to_numpy()\n",
    "\n",
    "# Get the label in the right format\n",
    "y = acc_balanced2['Accident_Severity'].astype(object).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the features for the remaining dataset\n",
    "features_res = acc_sub_res[acc_sub_res.columns[acc_sub_res.columns.isin(['Road_Class', 'Junction_Detail', 'Light_Conditions', \n",
    "                                             'Weather_Conditions', 'Road_Surface_Conditions', 'Vehicle_Type', 'Sex_of_Driver', \n",
    "                                             'Day_of_Week', 'Engine_Capacity_(CC)', 'Age_of_Driver', 'Age_of_Vehicle',\n",
    "                                             'Multiple_Vehicles_involved', 'Urban_Area', 'Month', 'Year', 'Hour_of_Day', 'Speed_limit'])]]\n",
    "                                             \n",
    "# Bring them into the desired format\n",
    "features_res = features_res.astype(object)\n",
    "features_res[['Multiple_Vehicles_involved','Urban_Area']] = features_res[['Multiple_Vehicles_involved','Urban_Area']].astype(int)\n",
    "\n",
    "# Apply one hot encoding to get category-indicating variables for each categorical feature\n",
    "X_res = pd.get_dummies(features_res, drop_first=False).to_numpy()\n",
    "\n",
    "# Get the label in the right format\n",
    "y_res = acc_sub_res['Accident_Severity'].astype(object).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a train-test split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include the residual X values, that are not included in the balanced dataset, to the test dataset.\n",
    "Xtest = np.concatenate([Xtest, X_res])\n",
    "\n",
    "# Include the residual y values, that are not included in the balanced dataset, to the test dataset.\n",
    "ytest = np.concatenate([ytest, y_res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[ 39946  33067]\n",
      " [198076 273860]]\n",
      "\n",
      "Classification Report\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Serious & Fatal       0.17      0.55      0.26     73013\n",
      "         Slight       0.89      0.58      0.70    471936\n",
      "\n",
      "       accuracy                           0.58    544949\n",
      "      macro avg       0.53      0.56      0.48    544949\n",
      "   weighted avg       0.80      0.58      0.64    544949\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n",
    "clf.fit(Xtrain, ytrain)\n",
    "yhat_knn = clf.predict(Xtest)\n",
    "print('Confusion Matrix')\n",
    "print('')\n",
    "print(confusion_matrix(ytest, yhat_knn))\n",
    "print('')\n",
    "print('Classification Report')\n",
    "print('')\n",
    "print(classification_report(ytest, yhat_knn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}